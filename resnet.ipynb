{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import re\n",
    "import pydicom\n",
    "import SimpleITK as sitk\n",
    "import astra\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_paths_with_id(root_directory, list):    \n",
    "    for dirpath, dirnames, filenames in os.walk(root_directory):\n",
    "        for name in dirnames + filenames:\n",
    "            if 'npy' in name:\n",
    "                # Construct the full path and add to list\n",
    "                full_path = os.path.join(dirpath, name)\n",
    "                img = np.load(full_path)\n",
    "                img[img<0] = 0\n",
    "                list.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_noi = '/home/haoran/task1/project/scatter'\n",
    "dic_clean = '/home/haoran/task1/project/clean'\n",
    "projections_noise = []\n",
    "projections = []\n",
    "find_paths_with_id(dic_clean, projections)\n",
    "find_paths_with_id(dic_noi, projections_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(projections_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.7473383"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity\n",
    "from skimage.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(original, processed):\n",
    "    slices = original.shape[0]\n",
    "    \n",
    "    mse_values = []\n",
    "    ssim_values = []\n",
    "    \n",
    "    # Determine the data range for floating-point images\n",
    "    data_range = original.max() - original.min()  # This assumes both images have the same scale\n",
    "    \n",
    "    for i in range(slices-1):\n",
    "        slice_original = original[ i,:, :]\n",
    "        slice_processed = processed[ i,:, :]\n",
    "        \n",
    "        # Compute MSE for the current slice\n",
    "        mse_slice = mean_squared_error(slice_original, slice_processed)\n",
    "        mse_values.append(mse_slice)\n",
    "        \n",
    "        # Compute SSIM for the current slice, including the data_range\n",
    "        ssim_slice = structural_similarity(slice_original, slice_processed, data_range=data_range)\n",
    "        ssim_values.append(ssim_slice)\n",
    "   \n",
    "# Calculate NMSE\n",
    "    numerator = np.sum((original - processed) ** 2)\n",
    "    denominator = np.sum(original ** 2)\n",
    "\n",
    "    nmse = numerator / denominator\n",
    "\n",
    "\n",
    "    # Average MSE and SSIM over all slices\n",
    "    ssim = np.std(ssim_values)\n",
    "    mse_avg = np.mean(mse_values)\n",
    "    ssim_avg = np.mean(ssim_values)\n",
    "    \n",
    "    # Compute PSNR for the entire 3D dataset, using the average MSE\n",
    "    max_pixel_value = data_range  # Adjusted to use the calculated data range\n",
    "    psnr_avg = 20 * np.log10(max_pixel_value / np.sqrt(mse_avg))\n",
    "    \n",
    "    return nmse, 100*ssim_avg, psnr_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet(data):\n",
    "    depth, height, width = data.shape\n",
    " \n",
    "    final_data = np.zeros((depth, height , width))\n",
    "    \n",
    "    for z in range(depth):\n",
    "        coeff = pywt.wavedec2(data[z], 'haar', level = 4)\n",
    "        hh0 = coeff[4][2]\n",
    "        hl0= coeff[4][1]\n",
    "        lh0 = coeff[4][0]\n",
    "        hh1 = coeff[3][2]\n",
    "        hl1 = coeff[3][1]\n",
    "        lh1 = coeff[3][0]\n",
    "        hh2 = coeff[2][2]\n",
    "        hl2 = coeff[2][1]\n",
    "        lh2 = coeff[2][0]\n",
    "        hh3 = coeff[1][2]\n",
    "        hl3 = coeff[1][1]\n",
    "        lh3 = coeff[1][0]\n",
    "        ll = coeff[0]\n",
    "        # print(hl0)\n",
    "        # print(ll)\n",
    "        final_data[z, 0:32, 0:32] = ll\n",
    "        final_data[z, 32:64, 32:64] = hh3  \n",
    "        final_data[z, 32:64, 0:32] = hl3\n",
    "        final_data[z, 0:32, 32:64] = lh3  \n",
    "\n",
    "        final_data[z, 64:128, 64:128] = hh2\n",
    "        final_data[z, 64:128, 0:64] = hl2\n",
    "        final_data[z, 0:64, 64:128] = lh2  \n",
    "\n",
    "        final_data[z, 128:256, 128:256] = hh1  \n",
    "        final_data[z, 128:256, 0:128] = hl1\n",
    "        final_data[z, 0:128, 128:256] = lh1  \n",
    "\n",
    "        final_data[z, 256:512, 256:512] = hh0  \n",
    "        final_data[z, 256:512, 0:256] = hl0\n",
    "        final_data[z, 0:256, 256:512] = lh0\n",
    "    \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_wavelet(final_data):\n",
    "    depth, height, width = final_data.shape\n",
    "    \n",
    "    data = np.zeros((depth, height, width))\n",
    "  \n",
    "    for z in range(depth):\n",
    "        ll = final_data[z, 0:32, 0:32] \n",
    "        hh3 =  final_data[z, 32:64, 32:64]  \n",
    "        hl3 = final_data[z, 32:64, 0:32]  \n",
    "        lh3 = final_data[z, 0:32, 32:64]   \n",
    "\n",
    "        hh2 = final_data[z, 64:128, 64:128] \n",
    "        hl2 = final_data[z, 64:128, 0:64]  \n",
    "        lh2 = final_data[z, 0:64, 64:128]    \n",
    "\n",
    "        hh1 = final_data[z, 128:256, 128:256]  \n",
    "        hl1 = final_data[z, 128:256, 0:128] \n",
    "        lh1 = final_data[z, 0:128, 128:256]  \n",
    "\n",
    "        hh0 = final_data[z, 256:512, 256:512] \n",
    "        hl0 = final_data[z, 256:512, 0:256] \n",
    "        lh0 = final_data[z, 0:256, 256:512] \n",
    "\n",
    "        coeff = [ll, (lh3, hl3, hh3), (lh2, hl2, hh2), (lh1, hl1, hh1), (lh0, hl0, hh0)]\n",
    "        data[z] = pywt.waverec2(coeff, 'haar')\n",
    "\n",
    "        \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww_target = []\n",
    "\n",
    "\n",
    "for projection in projections:\n",
    "    ww = wavelet(projection)\n",
    "    ww = (ww+12)/(70+12)\n",
    "    ww_target.append(ww)\n",
    "\n",
    "ww_input = []\n",
    "for projection in projections_noise:\n",
    "    ww = wavelet(projection)\n",
    "    ww = (ww+9)/58\n",
    "    ww_input.append(ww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0013726333092"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(ww_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013522246788287985"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(ww_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9900551772699123 0.003583884820705507\n",
      "1.0013726333092 0.013522246788287985\n"
     ]
    }
   ],
   "source": [
    "ww_target_array = np.array(ww_target)\n",
    "print(np.max(ww_target_array), np.min(ww_target_array))\n",
    "ww_target_array = np.expand_dims(ww_target_array,1)\n",
    "# ww_target_array = np.expand_dims(ww_target_array,0)\n",
    "ww_target_ten = torch.Tensor(ww_target_array)\n",
    "# ww_target_ten = torch.unsqueeze(ww_target_ten, 0)\n",
    "\n",
    "ww_input_array = np.array(ww_input)\n",
    "print(np.max(ww_input_array), np.min(ww_input_array))\n",
    "ww_input_array = np.expand_dims(ww_input_array,1)\n",
    "# ww_input_array = np.expand_dims(ww_input_array,0)\n",
    "ww_input_ten = torch.Tensor(ww_input_array)\n",
    "# ww_input_ten = torch.unsqueeze(ww_input_ten, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "dataset2 = TensorDataset(ww_input_ten, ww_target_ten)\n",
    "train, test = random_split(dataset2, (50,14))\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=1, shuffle=False)\n",
    "val_loader=DataLoader(test,batch_size=1,shuffle=False)\n",
    "test_loader = DataLoader(test, batch_size=1, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsampleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DownsampleBlock, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "        self.actv = nn.PReLU(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.actv(self.conv(x))\n",
    "\n",
    "\n",
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, cat_channels, out_channels):\n",
    "        super(UpsampleBlock, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv3d(in_channels + cat_channels, out_channels, 3, padding=1)\n",
    "        self.conv_t = nn.ConvTranspose3d(in_channels, in_channels, 2, stride=2)\n",
    "        self.actv = nn.PReLU(out_channels)\n",
    "        self.actv_t = nn.PReLU(in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        upsample, concat = x\n",
    "        upsample = self.actv_t(self.conv_t(upsample))\n",
    "        return self.actv(self.conv(torch.cat([concat, upsample], 1)))\n",
    "\n",
    "\n",
    "class InputBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(InputBlock, self).__init__()\n",
    "        self.conv_1 = nn.Conv3d(in_channels, out_channels, 3, padding=1)\n",
    "        self.conv_2 = nn.Conv3d(out_channels, out_channels, 3, padding=1)\n",
    "\n",
    "        self.actv_1 = nn.PReLU(out_channels)\n",
    "        self.actv_2 = nn.PReLU(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.actv_1(self.conv_1(x))\n",
    "        return self.actv_2(self.conv_2(x))\n",
    "\n",
    "\n",
    "class OutputBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutputBlock, self).__init__()\n",
    "        self.conv_1 = nn.Conv3d(in_channels, in_channels, 3, padding=1)\n",
    "        self.conv_2 = nn.Conv3d(in_channels, out_channels, 3, padding=1)\n",
    "\n",
    "        self.actv_1 = nn.PReLU(in_channels)\n",
    "        self.actv_2 = nn.PReLU(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.actv_1(self.conv_1(x))\n",
    "        return self.actv_2(self.conv_2(x))\n",
    "\n",
    "\n",
    "class DenoisingBlock(nn.Module):\n",
    "    def __init__(self, in_channels, inner_channels, out_channels):\n",
    "        super(DenoisingBlock, self).__init__()\n",
    "        self.conv_0 = nn.Conv3d(in_channels, inner_channels, 3, padding=1)\n",
    "        self.conv_1 = nn.Conv3d(in_channels + inner_channels, inner_channels, 3, padding=1)\n",
    "        self.conv_2 = nn.Conv3d(in_channels + 2 * inner_channels, inner_channels, 3, padding=1)\n",
    "        self.conv_3 = nn.Conv3d(in_channels + 3 * inner_channels, out_channels, 3, padding=1)\n",
    "\n",
    "        self.actv_0 = nn.PReLU(inner_channels)\n",
    "        self.actv_1 = nn.PReLU(inner_channels)\n",
    "        self.actv_2 = nn.PReLU(inner_channels)\n",
    "        self.actv_3 = nn.PReLU(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_0 = self.actv_0(self.conv_0(x))\n",
    "\n",
    "        out_0 = torch.cat([x, out_0], 1)\n",
    "        out_1 = self.actv_1(self.conv_1(out_0))\n",
    "\n",
    "        out_1 = torch.cat([out_0, out_1], 1)\n",
    "        out_2 = self.actv_2(self.conv_2(out_1))\n",
    "\n",
    "        out_2 = torch.cat([out_1, out_2], 1)\n",
    "        out_3 = self.actv_3(self.conv_3(out_2))\n",
    "\n",
    "        return out_3 + x\n",
    "\n",
    "\n",
    "class RDUNet(nn.Module):\n",
    "    r\"\"\"\n",
    "    Residual-Dense U-net for image denoising.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        channels = 1\n",
    "        filters_0 = 8\n",
    "        filters_1 = 2 * filters_0\n",
    "        filters_2 = 4 * filters_0\n",
    "        filters_3 = 8 * filters_0\n",
    "\n",
    "        # Encoder:\n",
    "        # Level 0:\n",
    "        self.input_block = InputBlock(channels, filters_0)\n",
    "        self.block_0_0 = DenoisingBlock(filters_0, filters_0 // 2, filters_0)\n",
    "        self.block_0_1 = DenoisingBlock(filters_0, filters_0 // 2, filters_0)\n",
    "        self.down_0 = DownsampleBlock(filters_0, filters_1)\n",
    "\n",
    "        # Level 1:\n",
    "        self.block_1_0 = DenoisingBlock(filters_1, filters_1 // 2, filters_1)\n",
    "        self.block_1_1 = DenoisingBlock(filters_1, filters_1 // 2, filters_1)\n",
    "        self.down_1 = DownsampleBlock(filters_1, filters_2)\n",
    "\n",
    "        # Level 2:\n",
    "        self.block_2_0 = DenoisingBlock(filters_2, filters_2 // 2, filters_2)\n",
    "        self.block_2_1 = DenoisingBlock(filters_2, filters_2 // 2, filters_2)\n",
    "        self.down_2 = DownsampleBlock(filters_2, filters_3)\n",
    "\n",
    "        # Level 3 (Bottleneck)\n",
    "        self.block_3_0 = DenoisingBlock(filters_3, filters_3 // 2, filters_3)\n",
    "        self.block_3_1 = DenoisingBlock(filters_3, filters_3 // 2, filters_3)\n",
    "\n",
    "        # Decoder\n",
    "        # Level 2:\n",
    "        self.up_2 = UpsampleBlock(filters_3, filters_2, filters_2)\n",
    "        self.block_2_2 = DenoisingBlock(filters_2, filters_2 // 2, filters_2)\n",
    "        self.block_2_3 = DenoisingBlock(filters_2, filters_2 // 2, filters_2)\n",
    "\n",
    "        # Level 1:\n",
    "        self.up_1 = UpsampleBlock(filters_2, filters_1, filters_1)\n",
    "        self.block_1_2 = DenoisingBlock(filters_1, filters_1 // 2, filters_1)\n",
    "        self.block_1_3 = DenoisingBlock(filters_1, filters_1 // 2, filters_1)\n",
    "\n",
    "        # Level 0:\n",
    "        self.up_0 = UpsampleBlock(filters_1, filters_0, filters_0)\n",
    "        self.block_0_2 = DenoisingBlock(filters_0, filters_0 // 2, filters_0)\n",
    "        self.block_0_3 = DenoisingBlock(filters_0, filters_0 // 2, filters_0)\n",
    "\n",
    "        self.output_block = OutputBlock(filters_0, channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        out_0 = self.input_block(inputs)    # Level 0\n",
    "        out_0 = self.block_0_0(out_0)\n",
    "        out_0 = self.block_0_1(out_0)\n",
    "\n",
    "        out_1 = self.down_0(out_0)          # Level 1\n",
    "        out_1 = self.block_1_0(out_1)\n",
    "        out_1 = self.block_1_1(out_1)\n",
    "\n",
    "        out_2 = self.down_1(out_1)          # Level 2\n",
    "        out_2 = self.block_2_0(out_2)\n",
    "        out_2 = self.block_2_1(out_2)\n",
    "\n",
    "        out_3 = self.down_2(out_2)          # Level 3 (Bottleneck)\n",
    "        out_3 = self.block_3_0(out_3)\n",
    "        out_3 = self.block_3_1(out_3)\n",
    "\n",
    "        out_4 = self.up_2([out_3, out_2])   # Level 2\n",
    "        out_4 = self.block_2_2(out_4)\n",
    "        out_4 = self.block_2_3(out_4)\n",
    "\n",
    "        out_5 = self.up_1([out_2, out_1])   # Level 1\n",
    "        out_5 = self.block_1_2(out_5)\n",
    "        out_5 = self.block_1_3(out_5)\n",
    "\n",
    "        out_6 = self.up_0([out_5, out_0])   # Level 0\n",
    "        out_6 = self.block_0_2(out_6)\n",
    "        out_6 = self.block_0_3(out_6)\n",
    "\n",
    "        return self.output_block(out_6) + inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train1(model1, train_loader, optimizer):\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    model1.train()\n",
    "    train_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x = model1(x)\n",
    "        \n",
    "        x1 = x[:,:,:, 0:32, 0:32]\n",
    "        x2 = x[:,:,:, 32:64, 32:64]  \n",
    "        x3 = x[:,:,:, 32:64, 0:32]  \n",
    "        x4 = x[:,:,:, 0:32, 32:64] \n",
    "\n",
    "        x5 = x[:,:,:, 64:128, 64:128]   \n",
    "        x6 = x[:,:,:, 64:128, 0:64]\n",
    "        x7 = x[:,:,:, 0:64, 64:128] \n",
    "        x8 = x[:,:,:, 128:256, 128:256]\n",
    "\n",
    "        x9 = x[:,:,:, 128:256, 0:128]\n",
    "        x10 = x[:,:,:, 0:128, 128:256]\n",
    "        x11 = x[:,:,:, 256:512, 256:512]\n",
    "        x12 = x[:,:,:, 256:512, 0:256]\n",
    "\n",
    "        x13 = x[:,:,:, 0:256, 256:512]\n",
    "\n",
    "        y1 = y[:,:,:, 0:32, 0:32]\n",
    "        y2 = y[:,:,:, 32:64, 32:64]  \n",
    "        y3 = y[:,:,:, 32:64, 0:32]  \n",
    "        y4 = y[:,:,:, 0:32, 32:64] \n",
    "\n",
    "        y5 = y[:,:,:, 64:128, 64:128]   \n",
    "        y6 = y[:,:,:, 64:128, 0:64]\n",
    "        y7 = y[:,:,:, 0:64, 64:128] \n",
    "        y8 = y[:,:,:, 128:256, 128:256]\n",
    "\n",
    "        y9 = y[:,:,:, 128:256, 0:128]\n",
    "        y10 = y[:,:,:, 0:128, 128:256]\n",
    "        y11 = y[:,:,:, 256:512, 256:512]\n",
    "        y12 = y[:,:,:, 256:512, 0:256]\n",
    "\n",
    "        y13 = y[:,:,:, 0:256, 256:512]\n",
    "        \n",
    "        loss = loss_fn(x1, y1) +loss_fn(x2, y2) +loss_fn(x3, y3)+ loss_fn(x4, y4)+ loss_fn(x5, y5) + loss_fn(x6, y6) +loss_fn(x7, y7)+loss_fn(x8, y8)+ loss_fn(x9, y9) +loss_fn(x10, y10) +loss_fn(x11, y11)+ loss_fn(x12, y12)+ loss_fn(x13, y13)  \n",
    "        # loss = 0.003*loss_fn(x1, y1) +0.032*loss_fn(x2, y2) +0.701*loss_fn(x3, y3)+ 0.018*loss_fn(x4, y4)+ 0.021*loss_fn(x5, y5) + 0.080*loss_fn(x6, y6) +0.02*loss_fn(x7, y7)+0.02*loss_fn(x8, y8)+ 0.025*loss_fn(x9, y9) +0.02*loss_fn(x10, y10) +0.02*loss_fn(x11, y11)+ 0.02*loss_fn(x12, y12)+ 0.02*loss_fn(x13, y13) \n",
    "\n",
    "        loss.backward()  # Accumulate gradients\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.step()  # Perform optimization step\n",
    "\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    return train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval() \n",
    "    val_loss = 0\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            x = model(x)\n",
    "            x1 = x[:,:,:, 0:32, 0:32]\n",
    "            x2 = x[:,:,:, 32:64, 32:64]  \n",
    "            x3 = x[:,:,:, 32:64, 0:32]  \n",
    "            x4 = x[:,:,:, 0:32, 32:64] \n",
    "\n",
    "            x5 = x[:,:,:, 64:128, 64:128]   \n",
    "            x6 = x[:,:,:, 64:128, 0:64]\n",
    "            x7 = x[:,:,:, 0:64, 64:128] \n",
    "            x8 = x[:,:,:, 128:256, 128:256]\n",
    "\n",
    "            x9 = x[:,:,:, 128:256, 0:128]\n",
    "            x10 = x[:,:,:, 0:128, 128:256]\n",
    "            x11 = x[:,:,:, 256:512, 256:512]\n",
    "            x12 = x[:,:,:, 256:512, 0:256]\n",
    "\n",
    "            x13 = x[:,:,:, 0:256, 256:512]\n",
    "\n",
    "            y1 = y[:,:,:, 0:32, 0:32]\n",
    "            y2 = y[:,:,:, 32:64, 32:64]  \n",
    "            y3 = y[:,:,:, 32:64, 0:32]  \n",
    "            y4 = y[:,:,:, 0:32, 32:64] \n",
    "\n",
    "            y5 = y[:,:,:, 64:128, 64:128]   \n",
    "            y6 = y[:,:,:, 64:128, 0:64]\n",
    "            y7 = y[:,:,:, 0:64, 64:128] \n",
    "            y8 = y[:,:,:, 128:256, 128:256]\n",
    "\n",
    "            y9 = y[:,:,:, 128:256, 0:128]\n",
    "            y10 = y[:,:,:, 0:128, 128:256]\n",
    "            y11 = y[:,:,:, 256:512, 256:512]\n",
    "            y12 = y[:,:,:, 256:512, 0:256]\n",
    "\n",
    "            y13 = y[:,:,:, 0:256, 256:512]\n",
    "                \n",
    "            # loss = 0.003*loss_fn(x1, y1) +0.032*loss_fn(x2, y2) +0.701*loss_fn(x3, y3)+ 0.018*loss_fn(x4, y4)+ 0.021*loss_fn(x5, y5) + 0.080*loss_fn(x6, y6) +0.02*loss_fn(x7, y7)+0.02*loss_fn(x8, y8)+ 0.025*loss_fn(x9, y9) +0.02*loss_fn(x10, y10) +0.02*loss_fn(x11, y11)+ 0.02*loss_fn(x12, y12)+ 0.02*loss_fn(x13, y13) \n",
    "        \n",
    "   \n",
    "            loss = loss_fn(x1, y1) +loss_fn(x2, y2) +loss_fn(x3, y3)+ loss_fn(x4, y4)+ loss_fn(x5, y5) + loss_fn(x6, y6) +loss_fn(x7, y7)+loss_fn(x8, y8)+ loss_fn(x9, y9) +loss_fn(x10, y10) +loss_fn(x11, y11)+ loss_fn(x12, y12)+ loss_fn(x13, y13) \n",
    "\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m val_loss_set\u001b[39m=\u001b[39m[]\n\u001b[1;32m      8\u001b[0m train_loss_set\u001b[39m=\u001b[39m[]\n\u001b[0;32m---> 10\u001b[0m myUNet1 \u001b[39m=\u001b[39m RDUNet()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(patience\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m \u001b[39m# myUNet1.to(device)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# myUNet1.load_state_dict(torch.load('/home/haoran/task1/save_model/model_ww0050.pth'))\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import os\n",
    "epoch_save = 10\n",
    "\n",
    "val_loss_set=[]\n",
    "train_loss_set=[]\n",
    "\n",
    "myUNet1 = RDUNet().to(device)\n",
    "early_stopping = EarlyStopping(patience=20, verbose=True)\n",
    "optimizer = optim.Adam( myUNet1.parameters(), lr=0.0001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=300, eta_min=0)\n",
    "for epoch in range(300):\n",
    "    train_loss = train1(myUNet1,train_loader, optimizer)\n",
    "    \n",
    "    val_loss = validate(myUNet1, val_loader)\n",
    "    scheduler.step()\n",
    "\n",
    "    print('epoch', str(epoch),':train_loss:',train_loss, 'val_loss:',val_loss)\n",
    "    # print(\"train_loss: %.6f, val_loss: %.6f\", % (train_loss, val_loss))\n",
    "\n",
    "    if (epoch+1) % epoch_save == 0:\n",
    "        save_path=os.path.join(\"/home/haoran/task1/save_model\", \"model_ww\" + str(epoch+1).zfill(4) + \".pth\")\n",
    "        torch.save(myUNet1.state_dict(), save_path)\n",
    "        \n",
    "\n",
    "    early_stopping(val_loss = val_loss, model=myUNet1.eval)\n",
    "\n",
    "   \n",
    "    save_path=os.path.join(\"/home/haoran/task1/save_model\", \"model_ww.pth\")\n",
    "    torch.save(myUNet1.state_dict(), save_path)\n",
    "    \n",
    "    # val_loss_set.append(val_loss)\n",
    "    train_loss_set.append(train_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myUNet1 = RDUNet()\n",
    "myUNet1.load_state_dict(torch.load(\"*\"))\n",
    "# need to retrain mse 210 sino 170  me 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [01:51,  7.99s/it]\n"
     ]
    }
   ],
   "source": [
    "wl = []\n",
    "wl_tar = []\n",
    "recon = []\n",
    "recon_target = []\n",
    "myUNet1.cpu()\n",
    "for (x,y),proj in tqdm(zip(test_loader,projections)):\n",
    "    # print(x.shape)\n",
    "    output = myUNet1(x)\n",
    "    output = np.reshape((output.detach().numpy()),(32,512, 512))\n",
    "    \n",
    "    wl.append(output)\n",
    "    output = (70+12)*output - 12\n",
    "    img = re_wavelet(output)\n",
    "    recon.append(img)\n",
    "    \n",
    "    target = np.reshape((y.detach().numpy()),(32,512,512))\n",
    "\n",
    "    wl_tar.append(target)\n",
    "    target = (70+12)*target - 12\n",
    "    target = re_wavelet(target)\n",
    "    recon_target.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12fab14baffc4e45824c43aa19c0dcd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=15, description='index', max=31), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_image(index)>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_image(index):\n",
    "    plt.imshow(recon_target[0][index,:,:], cmap='gray')\n",
    "    plt.title(f\"Image {index}\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "interact(plot_image, index=(0, recon_target[0].shape[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5263c745b30947e7900c21377a9813a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=15, description='index', max=31), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_image(index)>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_image(index):\n",
    "    plt.imshow(recon[0][index,:,:], cmap='gray')\n",
    "    plt.title(f\"Image {index}\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "interact(plot_image, index=(0, recon_target[0].shape[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84eece8a68184e9080ccc51e72c4be36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=15, description='index', max=31), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_image(index)>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_image(index):\n",
    "    plt.imshow(wl[0][index,:,:], cmap='gray')\n",
    "    plt.title(f\"Image {index}\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "interact(plot_image, index=(0, wl[0].shape[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b55fe86299348ada495c3fcde25a07d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=15, description='index', max=31), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_image(index)>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_image(index):\n",
    "    plt.imshow(wl_tar[0][index,:,:], cmap='gray')\n",
    "    plt.title(f\"Image {index}\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "interact(plot_image, index=(0, wl[0].shape[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = recon[0]-recon_target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67aee14232f24605b9f7db2422260804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=15, description='index', max=31), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_image(index)>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_image(index):\n",
    "    plt.imshow(temp[index,:,:], cmap='gray')\n",
    "    plt.title(f\"Image {index}\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "interact(plot_image, index=(0, recon_target[0].shape[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b24666e345a4c2f9027a09984abcfaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=15, description='index', max=31), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_image(index)>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_image(index):\n",
    "    plt.imshow(wl[0][index,:,:], cmap='gray')\n",
    "    plt.title(f\"Image {index}\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "interact(plot_image, index=(0, recon_target[0].shape[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: (5.5455216e-06, 1.8713496e-06), SSIM: (99.99376027011985, 0.001208096570093948), PSNR: (67.89076216380359, 0.8510168867694164)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "mse_ = []\n",
    "ssim_ = []\n",
    "psnr_ = []\n",
    "for a, b in zip(wl, wl_tar):\n",
    "    mse, ssim, psnr = compute_metrics(a, b)\n",
    "    mse_.append(mse)\n",
    "    ssim_.append(ssim)\n",
    "    psnr_.append(psnr)\n",
    "print(f\"MSE: {np.mean(mse_),np.std(mse_)}, SSIM: {np.mean(ssim_),np.std(ssim_)}, PSNR: {np.mean(psnr_),np.std(psnr_)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: (0.0005297821080679277, 0.00011584852215238191), SSIM: (97.42182720618158, 0.3869787891127376), PSNR: (43.210290443086215, 0.8817996182168156)\n"
     ]
    }
   ],
   "source": [
    "mse_ = []\n",
    "ssim_ = []\n",
    "psnr_ = []\n",
    "for a, b in zip(recon_target, recon):\n",
    "\n",
    "    mse, ssim, psnr = compute_metrics(a, b)\n",
    "    mse_.append(mse)\n",
    "    ssim_.append(ssim)\n",
    "    psnr_.append(psnr)\n",
    "print(f\"MSE: {np.mean(mse_),np.std(mse_)}, SSIM: {np.mean(ssim_),np.std(ssim_)}, PSNR: {np.mean(psnr_),np.std(psnr_)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79d6a5169fe49718885730cec92fe18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=15, description='index', max=31), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_image(index)>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_image(index):\n",
    "    plt.imshow(recon_target[0][index,:,:], cmap='gray')\n",
    "    plt.title(f\"Image {index}\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "interact(plot_image, index=(0, recon_target[0].shape[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15136e73dada4225a419ebb16d5eba9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=15, description='index', max=31), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_image(index)>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_image(index):\n",
    "    plt.imshow(recon[0][index,:,:], cmap='gray')\n",
    "    plt.title(f\"Image {index}\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "interact(plot_image, index=(0, recon_target[10].shape[0]-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "task1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
